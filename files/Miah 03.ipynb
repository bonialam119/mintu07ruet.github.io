{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data and explore the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read The data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data and see the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('C:/Users/mxm5116/Desktop/Data Mining/IMDB Dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the data\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  negative\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets, see the summary of the data set\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    25000\n",
       "positive    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the positive and negative number of sentiment\n",
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a. Divide the dataset as train, development and testÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now clear and normalized the data and divide again as normalized train, development and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "# Removing the html strips\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoove the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "data['review']=data['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now remove special character and apply function for the review colums\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "data['review']=data['review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming the text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "#Apply function on review column\n",
    "data['review']=data['review'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other review ha mention that after ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonder littl product the film techniqu is ve...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought thi wa a wonder way to spend time on...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic there a famili where a littl boy jake th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love in the time of money is a v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other review ha mention that after ...  positive\n",
       "1  A wonder littl product the film techniqu is ve...  positive\n",
       "2  I thought thi wa a wonder way to spend time on...  positive\n",
       "3  basic there a famili where a littl boy jake th...  negative\n",
       "4  petter mattei love in the time of money is a v...  positive"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other review ha mention that after ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonder littl product the film techniqu is ve...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought thi wa a wonder way to spend time on...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic there a famili where a littl boy jake th...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love in the time of money is a v...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  score\n",
       "0  one of the other review ha mention that after ...  positive      1\n",
       "1  A wonder littl product the film techniqu is ve...  positive      1\n",
       "2  I thought thi wa a wonder way to spend time on...  positive      1\n",
       "3  basic there a famili where a littl boy jake th...  negative      0\n",
       "4  petter mattei love in the time of money is a v...  positive      1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert positive=1 and negative=0 as numeric\n",
    "def posneg(x):\n",
    "    if x==\"negative\":\n",
    "        return 0\n",
    "    elif x==\"positive\":\n",
    "        return 1\n",
    "    return x\n",
    "\n",
    "filtered_score = data[\"sentiment\"].map(posneg)\n",
    "data[\"score\"] = filtered_score\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n",
      "(10000,)\n",
      "(40000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation for the model\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "import random\n",
    "X = data['review'].values\n",
    "y = data['sentiment'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see the normalized reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I did not watch the entir movi I could not watch the entir movi I stop the dvd after watch for half an hour and I suggest anyon think of watch themselv it stop themselv befor take the disc out of the casei like mafia movi both tragic and comic but corki romano can onli be describ as a tragic attempt at a mafia comedyth problem is corki romano simpli tri too hard to get the audienc to laugh the plot seem to be an excus for move chri kattan corki from one scene to anoth corki himself is complet overplay and lack subtleti or credul all hi strang manner come across as contriv chri kattan is clearli act rather than take a role it bounc you right out of the stori each scene is utterli predict the comed event that will occur on the set is obviou as soon as each scene is introduc In comedi such as Mr bean the disast caus by the titl charact are funni becaus you can empathis with the charact motiv and initi event and the situat the charact end up in is not telegraph corki howev give the feel that he is deliber screw up in a desper attempt to draw a laugh from the audienceif chri had not play such an alien charact who never realli connect with the other charact in the movi and whose behaviour is entir inexplic except for tri to draw laugh and the comedi scene werent so predict and stereotyp all the joke seem far too familiar thi movi could have been watchabl but it isnt dont watch it',\n",
       "       'A touch love stori reminisc of In the mood for love draw heavili on chines poetri and how thi is use by eastern peopl to commun feel to each other the stori focus on a schoolteach who want so much to be a model teacher as well as a good husband and father A senior student is veri attract to him As the stori unfold we see the emot below the surfac in hi 20 year marriag and how he grappl with the moral dilemma that face him A beauti and move stori',\n",
       "       'thi latterday fulci schlocker is a total abysm concoct deal with an incur gambler brett halsey who decid bluebeardstyl to pay off hi everris debt by seduc some of the ugliest bitch you will ever lay your eye on and who just happen to be wealthi widow the fulcipen script also contriv to incorpor a few blackli comed element which onli result in some unfunni busi involv a corps which wont stay put an opera singer victim who wont stop sing etc not to mention a doppelgang theme straight out of the student OF pragu although in thi case the two persona commun via prerecord radio messag In the end I cant say Im surpris that thi film show no sign of the sophist of mario bava hatchet for the honeymoon 1970 which it resembl in sever way and that it is content to mere pile up the disgustingli gori but nonetooconvinc effect of dismemb limb and squash or melt face with which ala fulci had by then becom complet associ',\n",
       "       'first of all I firmli believ that norwegian movi are continu get better from the tediou emot film of the 70 and 80 movi from thi place actual start to contain a bit of humour imagin actual comedi were made movi were actual start to get entertain and funni as oppos to long dark depress and boringdur the 90 and 00 sever realli great movi were made by a new gener of filmmak movi after movi were prais by critic and play load of money It becam the normthen came unitedminor spoiler it just simpli not funni not onc not ever but the thing is We think it funni becaus were use to norwegian movi to be funni especi with a cast like thi with a few realli funni comedian but they neither say nor do anyth funni where the humor show me the humor Is it the awkward clerk play by harald eia Is it the overact total ridicul unrealist footbal coach Is it the commentari by arn scheie the movi is just not funnybut that not my main rant about unit that name is the predict and it is here I fear that norwegian comedi have come to a standstil sinc I have seen thi in mani other movi as well all the time you just know it go to end well all charact are exactli as they are present in the start of the movi and everybodi get exactli what they deserv in the end there absolut no room for surpris at allal in all I can say that I sat with a bad feel after see thi movi It wa the one movi that made me realiz that we probabl need some new blood in norwegian movi make againr 16'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized Train Data set\n",
    "X_train[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not mani televis show appeal to quit as mani differ kind of fan like farscap doesi know youngster and 3040 year oldfan both male and femal in as mani differ countri as you can think of that just ador thi TV miniseri It ha element that can be found in almost everi other show on TV charact driven drama that could be from an australian soap opera yet in the same episod it ha scienc fact fiction that would give even the hardiest trekki a run for hi money in the brainbend stake wormhol theori time travel in true equat formmagnific It embrac cultur from all over the map as the possibl are endless have multipl star and therefor thousand of planet to choos fromwith such a broad scope it would be expect that noth would be abl to keep up the illus for long but here is where farscap realli come into it own elementit succe where all other have fail especi the like of star trek a univers with practic zero kao element they ran out of idea pretti quickli kept rehash them over the cours of 4 season they manag to keep the audienc attent use good continu and constant charact evolut with multipl thread to everi episod with uniqu person touch to camera that are specif to certain charact group within the whole thi structur allow for an extrem larg area of subject matter as loyalti are forg and broken in mani way on mani mani issu I happen to see the pilot premier in pass and just had to keep tune in after that to see if crichton would ever get the girl after see them all on televis I wa delight to see them avail on dvd I have to admit that it wa the onli thing that kept me sane whilst I had to do a 12 hour night shift and develop chronic insomniafarscap wa the onli thing to get me through those extrem long nightsdo yourself a favour watch the pilot and see what I meanfarscap comet',\n",
       "       'the film quickli get to a major chase scene with ever increas destruct the first realli bad thing is the guy hijack steven seagal would have been beaten to pulp by seagal drive but that probabl would have end the whole premis for the movieit seem like they decid to make all kind of chang in the movi plot so just plan to enjoy the action and do not expect a coher plot turn ani sens of logic you may have it will reduc your chanc of get a headachei doe give me some hope that steven seagal is tri to move back toward the type of charact he portray in hi more popular movi',\n",
       "       'jane austen would definit approv of thi onegwyneth paltrow doe an awesom job captur the attitud of emma she is funni without be excess silli yet eleg she put on a veri convinc british accent not be british myself mayb Im not the best judg but she fool mesh wa also excel in slide doorsi sometim forget she american also brilliant are jeremi northam and sophi thompson and phyllida law emma thompson sister and mother as the bate women they nearli steal the showand Ms law doesnt even have ani lineshighli recommend',\n",
       "       'expect were somewhat high for me when I went to see thi movi after all I thought steve carel could do no wrong come off of great movi like anchorman the 40 yearold virgin and littl miss sunshin boy wa I wrongil start with what is right with thi movi at certain point steve carel is allow to be steve carel there are a hand of moment in the film that made me laugh and it due almost entir to him be given the wiggleroom to do hi thing he an undoubtedli talent individu and it a shame that he sign on to what turn out to be in my opinion a total trainwreckwith that out of the way ill discuss what went horrifyingli wrongth film begin with dan burn a widow with three girl who is be consid for a nation syndic advic column He prepar hi girl for a famili reunion where hi extend rel gather for some time with each otherth famili is high atop the list of thing that make thi an aw movi No famili behav like thi it almost as if theyv been transport from pleasantvil or leav it to beaver they are a caricatur of what we think a famili is when were 7 It reach the point where they becom obnoxi and simpli frustrat touch footbal crossword puzzl competit famili bowl and talent show are not how actual peopl behav it almost sickeninganoth big flaw is the woman carel is suppos to be fall for observ her in her first scene with steve carel is like watch a stroke victim tri to be rehabilit what I imagin is suppos to be uniqu and origin in thi woman come off as mildli retardedit make me think that thi movi is take place on anoth planet I left the theater wonder what I just saw after think further I dont think it wa much'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data set\n",
    "X_test[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b.\tBuild a vocabulary as list. \n",
    "ï§\t     [âtheâ âIâ âhappyâ â¦ ] \n",
    "# You may omit rare words for example if the occurrence is less than five times\n",
    "#  A reverse index as the key value might be handy\n",
    "    {âtheâ: 0, âIâ:1, âhappyâ:2 , â¦ }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_voca='.'.join(X_train)\n",
    "train_voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_voca='.'.join(X_test)\n",
    "test_voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foovec = CountVectorizer(min_df=1, tokenizer=nltk.word_tokenize)\n",
    "train_counts = foovec.fit_transform(X_train)\n",
    "print(train_counts)\n",
    "train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foovec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from collections import Counter\n",
    "# print the size of the vocab\n",
    "print(len(foovec.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may omit rare words for example if the occurrence is less than five times\n",
    "# keep tokens with a min occurrence\n",
    "min_occurane = 5\n",
    "tokens = [k for k,c in foovec.vocabulary_.items() if c >= min_occurane]\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c.\tCalculate the following probability\n",
    "ï§\tProbability of the occurrence\n",
    "â¢\tP[âtheâ] = num of documents containing âtheâ / num of all documents\n",
    "ï§\tConditional probability based on the sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"the\"]\n",
    "sentences = X_train\n",
    "count=0\n",
    "for sentence in sentences :\n",
    "     for word in words :\n",
    "           if word in sentence :\n",
    "            count=count+1\n",
    "            #print(count)\n",
    "            #print(count)\n",
    "num_of_documents_containing_the=count\n",
    "print(num_of_documents_containing_the)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_all_documents=40000\n",
    "print(num_of_all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Probability_of_the=num_of_documents_containing_the/num_of_all_documents\n",
    "print(Probability_of_the)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â¢\tP[âtheâ | Positive]  = # of positive documents containing âtheâ / num of all positive review documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now take the positive sentiment data from training set\n",
    "train_data=data[:4000]\n",
    "positive_docs=train_data.loc[train_data['sentiment']!=0]\n",
    "positive_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the list of positive sentiment\n",
    "train_pos_reviews=positive_docs['review']\n",
    "train_pos_voca=train_pos_reviews.values.tolist()\n",
    "train_pos_voca[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the positive sentiment with single dot\n",
    "'.'.join(train_pos_voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate the number of positive documents having the\n",
    "words=[\"the\"]\n",
    "sentences = train_pos_voca\n",
    "count=0\n",
    "for sentence in sentences :\n",
    "     for word in words :\n",
    "           if word in sentence :\n",
    "            count=count+1\n",
    "            #print(count)\n",
    "            #print(count)\n",
    "num_of_pos_documents_containing_the=count\n",
    "print(num_of_pos_documents_containing_the)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the totl positive documents in training data set\n",
    "num_of_all_pos_documents=positive_docs['review'].count()\n",
    "print(num_of_all_pos_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate P[âtheâ | Positive]  = # of positive documents containing âtheâ / num of all positive review documents\n",
    "probability_0f_the_in_positive_docs=num_of_pos_documents_containing_the/num_of_all_pos_documents\n",
    "print(probability_0f_the_in_positive_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d.\tCalculate accuracy using dev dataset \n",
    "ï§\tConduct five fold cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data in vector fpormate\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_train = tf_idf_vect.fit_transform(X_train)\n",
    "tf_idf_test = tf_idf_vect.transform(X_test)\n",
    "\n",
    "alpha_range = list(np.arange(1,50,5))\n",
    "len(alpha_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take different values of alpha in cross validation \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "alpha_scores=[]\n",
    "\n",
    "for a in alpha_range:\n",
    "    clf = MultinomialNB(alpha=a)\n",
    "    scores = cross_val_score(clf, tf_idf_train, y_train, cv=5, scoring='accuracy')\n",
    "    alpha_scores.append(scores.mean())\n",
    "    print(a,scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot b/w misclassification error and CV mean score.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MSE = [1 - x for x in alpha_scores]\n",
    "\n",
    "\n",
    "optimal_alpha_bnb = alpha_range[MSE.index(min(MSE))]\n",
    "\n",
    "# plot misclassification error vs alpha\n",
    "plt.plot(alpha_range, MSE)\n",
    "\n",
    "plt.xlabel('hyperparameter alpha')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_alpha_bnb\n",
    "\n",
    "# For alpha =1, we have got minimum misscalculation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see Naive bayes model\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(tf_idf_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred_test, normalize=True) * float(100)\n",
    "print('\\n****Test accuracy is',(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see the confusion matrix to see the performance in visualization of classification algorithm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "cm_test = confusion_matrix(y_test,y_pred_test)\n",
    "cm_test\n",
    "sns.heatmap(cm_test,annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see the train acuracy\n",
    "y_pred_train = clf.predict(tf_idf_train)\n",
    "acc = accuracy_score(y_train, y_pred_train, normalize=True) * float(100)\n",
    "print('\\n****Train accuracy is %d%%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e.\tDo following experiments\n",
    "ï§\tCompare the effect of Smoothing\n",
    "ï§\tDerive Top 10 words that predicts positive and negative class \n",
    " â¢\tP[Positive| word] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see the effect of smoothing\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will remove stop words as it does not carry significant meaning and will store positive and negative word for selections\n",
    "stop = set(stopwords.words('english')) \n",
    "sno = nltk.stem.SnowballStemmer('english') \n",
    "def cleanhtml(sentence): \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): \n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] \n",
    "all_negative_words=[] \n",
    "s=''\n",
    "for sent in data['review'].values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent) \n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (data['sentiment'].values)[i] == 1: \n",
    "                        all_positive_words.append(s) \n",
    "                    if(data['sentiment'].values)[i] == 0:\n",
    "                        all_negative_words.append(s) \n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    \n",
    "    str1 = b\" \".join(filtered_sentence) \n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_positive_words = len(all_positive_words)\n",
    "total_negative_words = len(all_negative_words)\n",
    "print(total_positive_words)\n",
    "print(total_negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "apw = random.sample(all_positive_words, 10000)\n",
    "anw = random.sample(all_negative_words, 10000)\n",
    "freq_negative_words = {x:anw.count(x) for x in anw}\n",
    "freq_positive_words = {x:apw.count(x) for x in apw}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see positive sentiment first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "for key in freq_positive_words:\n",
    "    prob = freq_positive_words[key]/total_positive_words\n",
    "    lst.append([key,prob])\n",
    "table_positive = pd.DataFrame(lst,columns=['positive_words','probability'])\n",
    "table_positive = table_positive.sort_values('probability', axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last')\n",
    "table_positive.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "posi={}\n",
    "i=0\n",
    "for key, value in sorted(freq_positive_words.items(), key = itemgetter(1), reverse = True):\n",
    "    if(i>10):\n",
    "        break\n",
    "    posi[key]=value\n",
    "    i+=1\n",
    "posi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(posi)), list(posi.values()), align='center')\n",
    "plt.xticks(range(len(posi)), list(posi.keys()))\n",
    "\n",
    "print(\"Top 10 words that predicts positive sentiment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see top 10 negative sentiment words\n",
    "lst=[]\n",
    "for key in freq_negative_words:\n",
    "    prob = freq_negative_words[key]/total_negative_words\n",
    "    lst.append([key,prob])\n",
    "table_negative = pd.DataFrame(lst,columns=['negative_words','probability'])\n",
    "table_negative = table_negative.sort_values('probability', axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last')\n",
    "table_negative.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nega={}\n",
    "i=0\n",
    "for key, value in sorted(freq_negative_words.items(), key = itemgetter(1), reverse = True):\n",
    "    if(i>10):\n",
    "        break\n",
    "    nega[key]=value\n",
    "    i+=1\n",
    "nega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(nega)), list(nega.values()), align='center')\n",
    "plt.xticks(range(len(nega)), list(nega.keys()))\n",
    "\n",
    "print(\"Top 10 words that predicts negative sentiment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f.\tUsing the test dataset\n",
    "ï§\tUse the optimal hyperparameters you found in the step e, and use it to calculate the final accuracy.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "01. https://www.kaggle.com/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews\n",
    "02. https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184\n",
    "03. https://www.dataquest.io/blog/naive-bayes-tutorial/\n",
    "04. https://levelup.gitconnected.com/movie-review-sentiment-analysis-with-naive-bayes-machine-learning-from-scratch-part-v-7bb869391bab\n",
    "05. https://github.com/krsatyam1996/IMDB-sentiment-analysis-using-naive-bayes/blob/master/movie_review.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
